{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "import random\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labels:\\n0 - other\\n1 - head non-standard plane\\n2 - head standard plane\\n3 - femur non-standard plane\\n4 - femur standard plane\\n5 - femur non standard plane\\n6 - femur standard plane'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"labels:\n",
    "0 - other\n",
    "1 - head non-standard plane\n",
    "2 - head standard plane\n",
    "3 - femur non-standard plane\n",
    "4 - femur standard plane\n",
    "5 - femur non standard plane\n",
    "6 - femur standard plane\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/biometry_train_scaled_size.csv')\n",
    "val = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/biometry_val_scaled_size.csv')\n",
    "test = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/biometry_test_scaled_size.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_org = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_train.csv')\n",
    "test_org = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_test.csv')\n",
    "\n",
    "val_org = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['days'] = train_org['days']\n",
    "test['days'] = test_org['days']\n",
    "val['days'] = val_org['days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/class_data/biometry_train_all.csv', index=False)\n",
    "val.to_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/class_data/biometry_val_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/biometry_train_scaled_size_all.csv')\n",
    "val = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/biometry_val_scaled_size_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_vids = (train['video'].value_counts() > 3)\n",
    "videos = train['video'].unique()\n",
    "long_vids = videos[long_vids]\n",
    "train_filtered = train[train['video'].isin(long_vids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/biometry_train_scaled_size_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'video': data['video'].unique()}).to_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/videos_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/biometry_val_scaled_size_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['9_2', '19_2', '25_2', '30_2', '38_2', '77_2', '88_2', '105_2',\n",
       "       '129_2', '169_2', '222_2', '237_2', '243_2', '245_2', '272_2',\n",
       "       '294_2', '295_2', '308_2', '322_2', '343_2', '352_2', '410_2',\n",
       "       '436_2', '447_2', '474_2', '489_2', '594_2', '2_3', '83_3', '38_3',\n",
       "       '272_3', '294_3', '295_3', '343_3', '376_3', '378_3', '409_3',\n",
       "       '453_3', '474_3', '521_3', '5_3', '20_3', '33_3', '39_3', '50_3',\n",
       "       '56_3', '68_3', '87_3', '90_3', '116_3', '123_3', '148_3', '168_3',\n",
       "       '171_3', '180_3', '182_3', '198_3', '199_3', '206_3', '218_3',\n",
       "       '249_3', '259_3', '276_3', '279_3', '315_3', '326_3', '330_3',\n",
       "       '332_3', '342_3', '354_3', '359_3', '367_3', '377_3', '383_3',\n",
       "       '385_3', '386_3', '401_3', '420_3', '426_3', '462_3', '472_3',\n",
       "       '485_3', '500_3', '525_3', '526_3', '533_3', '584_3', '587_3',\n",
       "       '590_3', '598_3', '600_3', '604_3', '611_3', '636_3', '653_3',\n",
       "       '670_3', '672_3', '680_3', '2_1', '4_1', '15_1', '45_1', '49_1',\n",
       "       '52_1', '65_1', '66_1', '75_1', '83_1'], dtype=object)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val['video'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'video': data_val['video'].unique()}).to_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/videos_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Class</th>\n",
       "      <th>video</th>\n",
       "      <th>measures</th>\n",
       "      <th>ps</th>\n",
       "      <th>frames_n</th>\n",
       "      <th>measure_scaled</th>\n",
       "      <th>days</th>\n",
       "      <th>frame_loc</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>height_org</th>\n",
       "      <th>width_org</th>\n",
       "      <th>measure_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6_2_35</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>86.49360</td>\n",
       "      <td>115.32480</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6_2_36</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>86.49360</td>\n",
       "      <td>115.32480</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_2_37</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>86.49360</td>\n",
       "      <td>115.32480</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_2_38</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>86.49360</td>\n",
       "      <td>115.32480</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_2_39</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>86.49360</td>\n",
       "      <td>115.32480</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36250</th>\n",
       "      <td>117_1_40</td>\n",
       "      <td>2</td>\n",
       "      <td>117_1</td>\n",
       "      <td>19.85</td>\n",
       "      <td>0.108639</td>\n",
       "      <td>44</td>\n",
       "      <td>0.841410</td>\n",
       "      <td>161</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>78.22008</td>\n",
       "      <td>104.29344</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.563345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36251</th>\n",
       "      <td>117_1_41</td>\n",
       "      <td>2</td>\n",
       "      <td>117_1</td>\n",
       "      <td>19.85</td>\n",
       "      <td>0.108639</td>\n",
       "      <td>44</td>\n",
       "      <td>0.841410</td>\n",
       "      <td>161</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>78.22008</td>\n",
       "      <td>104.29344</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.563345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36252</th>\n",
       "      <td>117_1_42</td>\n",
       "      <td>2</td>\n",
       "      <td>117_1</td>\n",
       "      <td>19.85</td>\n",
       "      <td>0.108639</td>\n",
       "      <td>44</td>\n",
       "      <td>0.841410</td>\n",
       "      <td>161</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>78.22008</td>\n",
       "      <td>104.29344</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.563345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36253</th>\n",
       "      <td>117_1_43</td>\n",
       "      <td>2</td>\n",
       "      <td>117_1</td>\n",
       "      <td>19.85</td>\n",
       "      <td>0.108639</td>\n",
       "      <td>44</td>\n",
       "      <td>0.841410</td>\n",
       "      <td>161</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>78.22008</td>\n",
       "      <td>104.29344</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.563345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36254</th>\n",
       "      <td>117_1_44</td>\n",
       "      <td>2</td>\n",
       "      <td>117_1</td>\n",
       "      <td>19.85</td>\n",
       "      <td>0.108639</td>\n",
       "      <td>44</td>\n",
       "      <td>0.841410</td>\n",
       "      <td>161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.22008</td>\n",
       "      <td>104.29344</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.563345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36255 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  Class  video  measures        ps  frames_n  measure_scaled  \\\n",
       "0        6_2_35      4    6_2     16.47  0.120130        51        0.618863   \n",
       "1        6_2_36      4    6_2     16.47  0.120130        51        0.618863   \n",
       "2        6_2_37      4    6_2     16.47  0.120130        51        0.618863   \n",
       "3        6_2_38      4    6_2     16.47  0.120130        51        0.618863   \n",
       "4        6_2_39      4    6_2     16.47  0.120130        51        0.618863   \n",
       "...         ...    ...    ...       ...       ...       ...             ...   \n",
       "36250  117_1_40      2  117_1     19.85  0.108639        44        0.841410   \n",
       "36251  117_1_41      2  117_1     19.85  0.108639        44        0.841410   \n",
       "36252  117_1_42      2  117_1     19.85  0.108639        44        0.841410   \n",
       "36253  117_1_43      2  117_1     19.85  0.108639        44        0.841410   \n",
       "36254  117_1_44      2  117_1     19.85  0.108639        44        0.841410   \n",
       "\n",
       "       days  frame_loc    height      width  height_org  width_org  \\\n",
       "0       147   0.686275  86.49360  115.32480         720        960   \n",
       "1       147   0.705882  86.49360  115.32480         720        960   \n",
       "2       147   0.725490  86.49360  115.32480         720        960   \n",
       "3       147   0.745098  86.49360  115.32480         720        960   \n",
       "4       147   0.764706  86.49360  115.32480         720        960   \n",
       "...     ...        ...       ...        ...         ...        ...   \n",
       "36250   161   0.909091  78.22008  104.29344         720        960   \n",
       "36251   161   0.931818  78.22008  104.29344         720        960   \n",
       "36252   161   0.954545  78.22008  104.29344         720        960   \n",
       "36253   161   0.977273  78.22008  104.29344         720        960   \n",
       "36254   161   1.000000  78.22008  104.29344         720        960   \n",
       "\n",
       "       measure_normalized  \n",
       "0                0.457089  \n",
       "1                0.457089  \n",
       "2                0.457089  \n",
       "3                0.457089  \n",
       "4                0.457089  \n",
       "...                   ...  \n",
       "36250            0.563345  \n",
       "36251            0.563345  \n",
       "36252            0.563345  \n",
       "36253            0.563345  \n",
       "36254            0.563345  \n",
       "\n",
       "[36255 rows x 14 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = '6_2_35'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "idb = data.query('index == @index').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6_2_35'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_vids = (val['video'].value_counts() > 3)\n",
    "videos = val['video'].unique()\n",
    "long_vids = videos[long_vids]\n",
    "val_filtered = val[val['video'].isin(long_vids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_filtered.to_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/key_frame_data/biometry_val_all_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(num, min_value, max_value):\n",
    "   return max(min(num, max_value), min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video_Loader():\n",
    "    def __init__(self, root, videos_path, ann_path, transform=None, target_transform=None, img_scaling = False):\n",
    "        \n",
    "        self.data_path = root\n",
    "        self.ann_path = ann_path\n",
    "        self.videos = pd.read_csv(videos_path)\n",
    "        self.data = pd.read_csv(self.ann_path)\n",
    "        self.img_scaling = img_scaling\n",
    "        \n",
    "        \n",
    "    def _load_image(self, path):\n",
    "        try:\n",
    "            im = Image.open(path)\n",
    "            im.convert('RGB')\n",
    "        except:\n",
    "            print(\"ERROR IMG LOADED: \", path)\n",
    "            random_img = np.random.rand(224, 224, 3) * 255\n",
    "            im = Image.fromarray(np.uint8(random_img))\n",
    "        return im\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def _load_item(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        idb = self.data[data['index'] == index]\n",
    "        frame_idx = idb[0]\n",
    "        Class = torch.tensor(idb[1])\n",
    "        video = idb[2]\n",
    "        measure = torch.tensor(idb[3])\n",
    "        ps = torch.tensor(idb[4])\n",
    "        frames_n = torch.tensor(idb[5])\n",
    "        measure_scaled = torch.tensor(idb[6], dtype=torch.float32)\n",
    "        days_normalized = torch.tensor(idb[7], dtype=torch.float32)\n",
    "        frame_loc = torch.tensor(idb[8], dtype=torch.float32)\n",
    "        height = torch.tensor(idb[9])\n",
    "        width = torch.tensor(idb[10])\n",
    "        measure_normalized = torch.tensor(idb[13], dtype=torch.float32)\n",
    "        images = self._load_image(self.data_path  + frame_idx + '.png')\n",
    "        \n",
    "        new_height = clamp(int(height*2.161191086437513), 0, 512)\n",
    "        new_width = clamp(int(width*2.161191086437513), 0, 512)\n",
    "        if self.img_scaling:\n",
    "            padding = A.PadIfNeeded(min_height=512, min_width=512, border_mode=0, value=0, mask_value=0, always_apply=False, p=1.0)\n",
    "            rescale = A.Resize(new_height, new_width)\n",
    "            images = rescale(image = images)['image']\n",
    "            images = padding(image=images)['image']\n",
    "            images = np.expand_dims(images, 2)\n",
    "            t = transforms.Compose([transforms.ToTensor(),])\n",
    "            images = t(images)\n",
    "        else:\n",
    "            images = np.expand_dims(images, 2)\n",
    "            t = transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Resize((450, 600)),\n",
    "            transforms.Pad((0, 0, 0, 150), fill = 0, padding_mode = 'constant'),\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.Normalize(mean=0.1354949, std=0.18222201)])\n",
    "            images = t(images)\n",
    "        if self.transform is not None:\n",
    "            images = self.transform(images)\n",
    "\n",
    "        return images, Class, measure, ps, frames_n, measure_scaled, index, days_normalized, frame_loc, measure_normalized\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        video = self.videos[index]\n",
    "        batch = self.data[self.data['video'] == video].sample(8)\n",
    "        frame_idx = batch['index']\n",
    "        images = list()\n",
    "        Classes = list()\n",
    "        indexes = list()\n",
    "        for i in frame_idx:\n",
    "            image, Class, measure, ps, frame_n, measure_scaled, index, days_normalized, frame_loc, measure_normalized = self._load_item(i)\n",
    "            images.append(image)\n",
    "            Classes.append(Class)\n",
    "            indexes.append(index)\n",
    "        return images, Classes, measure_scaled, ps, frame_n, measure_scaled, index, days_normalized, frame_loc, measure_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_padding(features, max_length, split_sizes):\n",
    "    padded_output = []\n",
    "    for i, feature in enumerate(features):\n",
    "        padding_length = max_length - split_sizes[i]\n",
    "        padded_seq = torch.nn.functional.pad(feature, (0, padding_length, 0, 0, 0, 0), mode='constant', value=0)\n",
    "        padded_output.append(padded_seq)\n",
    "    padded_output = torch.stack(padded_output)\n",
    "    return padded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_seq = torch.ones(1, 1280, 13) # org lens: 3, 2, 4, 4\n",
    "split_sizes = [3, 2, 4, 4]\n",
    "tensor_list2 = [original_seq[:, :, i:i+split_size] for i, split_size in enumerate(split_sizes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = torch.split(original_seq, split_size_or_sections = split_sizes, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_496040/2548820828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor_list2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "(list(tensor_list) == tensor_list2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_496040/3760656076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq = features_padding(tensor_list, 8, split_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 1280, 8])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def mask_sequence(padded_seq, org_seq_lens):  \n",
    "    \n",
    "    # Define the padded sequence\n",
    "    padded_seq_len = padded_seq.size(-1)\n",
    "    batch_len = padded_seq.size(0)\n",
    "    # Define the mask tensor\n",
    "    mask = torch.zeros((batch_len, padded_seq_len, padded_seq_len), dtype=torch.float32)\n",
    "    \n",
    "    # Set the non-padding elements to 1's\n",
    "    for i in range(batch_len):\n",
    "        mask[i, :, :org_seq_lens[i]] = 1\n",
    "    \n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padded_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask_sequence(padded_seq, split_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq = padded_seq.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1280, 8])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax(dim = 2)\n",
    "keys = padded_seq*torch.ones(4, 1280, 8)\n",
    "queries = padded_seq*torch.ones(4, 1280, 8)\n",
    "values = padded_seq*torch.ones(4, 1280, 8)\n",
    "\n",
    "matmul = torch.matmul(queries.permute(0, 2, 1), keys) # (batch_size, n_channels, n_frames)\n",
    "matmul.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul masked tensor([[[ 1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20]],\n",
      "\n",
      "        [[ 1.2800e+03,  1.2800e+03, -1.0000e+20, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 1.2800e+03,  1.2800e+03, -1.0000e+20, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0000e+20, -1.0000e+20, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20]],\n",
      "\n",
      "        [[ 1.2800e+03,  1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 1.2800e+03,  1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 1.2800e+03,  1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 1.2800e+03,  1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20]],\n",
      "\n",
      "        [[ 1.2800e+03,  1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 1.2800e+03,  1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 1.2800e+03,  1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 1.2800e+03,  1.2800e+03,  1.2800e+03,  1.2800e+03, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+20,\n",
      "          -1.0000e+20, -1.0000e+20, -1.0000e+20]]])\n"
     ]
    }
   ],
   "source": [
    "if mask is not None:\n",
    "    matmul_masked = matmul.masked_fill(mask == 0, -1e20)\n",
    "    print('matmul masked', matmul_masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul_masked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax tensor([[[0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "softmax_output = softmax(matmul_masked) # (batch_size, n_channels, n_frames)\n",
    "print('softmax', softmax_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_map tensor([[[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.]]])\n",
      "attention_map torch.Size([4, 1280, 8])\n"
     ]
    }
   ],
   "source": [
    "attention_map = torch.matmul(values, softmax_output) # (batch_size, n_channels, n_frames)\n",
    "print('attention_map', attention_map)\n",
    "print('attention_map', attention_map.shape)\n",
    "#print('attention_map', attention_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 8])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq[:, :3, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand(5, 1280, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1280, 8])\n",
      "torch.Size([1280, 8])\n",
      "torch.Size([1280, 8])\n",
      "torch.Size([1280, 8])\n",
      "torch.Size([1280, 8])\n"
     ]
    }
   ],
   "source": [
    "for i in test:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_sizes = [3, 2, 4, 4]\n",
    "org_batch = [torch.rand(i, 1, 512, 512) for i in split_sizes]\n",
    "test_batch = torch.cat(org_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_unbinded = torch.split(test_batch, split_size_or_sections= split_sizes, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.rand(1, 1280, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Padding length too large",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_496040/3724981095.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpadded_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_496040/2767054824.py\u001b[0m in \u001b[0;36mfeatures_padding\u001b[0;34m(features, max_length, split_sizes)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpadding_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msplit_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpadded_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpadded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpadded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Padding length too large"
     ]
    }
   ],
   "source": [
    "padded_seq = features_padding(features, 8, split_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_batch_unbinded[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_batch_unbinded) == len(split_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (test_batch_unbinded[2] == org_batch[2]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(org_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b772ba6196d99b64d9019a11b57c24f8066632039bdf84a783d1d6c99c4aa12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
