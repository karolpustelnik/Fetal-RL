{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "import random\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labels:\\n0 - other\\n1 - head non-standard plane\\n2 - head standard plane\\n3 - femur non-standard plane\\n4 - femur standard plane\\n5 - femur non standard plane\\n6 - femur standard plane'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"labels:\n",
    "0 - other\n",
    "1 - head non-standard plane\n",
    "2 - head standard plane\n",
    "3 - femur non-standard plane\n",
    "4 - femur standard plane\n",
    "5 - femur non standard plane\n",
    "6 - femur standard plane\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/biometry_train_scaled_size.csv')\n",
    "val = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/biometry_val_scaled_size.csv')\n",
    "test = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/biometry_test_scaled_size.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_org = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_train.csv')\n",
    "test_org = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_test.csv')\n",
    "\n",
    "val_org = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['days'] = train_org['days']\n",
    "test['days'] = test_org['days']\n",
    "val['days'] = val_org['days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/class_data/biometry_train_all.csv', index=False)\n",
    "val.to_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/class_data/biometry_val_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/biometry_train_scaled_size_all.csv')\n",
    "val = pd.read_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/biometry_val_scaled_size_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_vids = (train['video'].value_counts() > 3)\n",
    "videos = train['video'].unique()\n",
    "long_vids = videos[long_vids]\n",
    "train_filtered = train[train['video'].isin(long_vids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Class</th>\n",
       "      <th>video</th>\n",
       "      <th>measures</th>\n",
       "      <th>ps</th>\n",
       "      <th>frames_n</th>\n",
       "      <th>measure_scaled</th>\n",
       "      <th>days</th>\n",
       "      <th>frame_loc</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>height_org</th>\n",
       "      <th>width_org</th>\n",
       "      <th>measure_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6_2_35</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>86.493600</td>\n",
       "      <td>115.324800</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6_2_36</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>86.493600</td>\n",
       "      <td>115.324800</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6_2_37</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>86.493600</td>\n",
       "      <td>115.324800</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_2_38</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>86.493600</td>\n",
       "      <td>115.324800</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_2_39</td>\n",
       "      <td>4</td>\n",
       "      <td>6_2</td>\n",
       "      <td>16.47</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>51</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>147</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>86.493600</td>\n",
       "      <td>115.324800</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>0.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33702</th>\n",
       "      <td>490_3_248</td>\n",
       "      <td>6</td>\n",
       "      <td>490_3</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>310</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>225</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>134.004264</td>\n",
       "      <td>178.672352</td>\n",
       "      <td>852</td>\n",
       "      <td>1136</td>\n",
       "      <td>0.131091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33703</th>\n",
       "      <td>490_3_249</td>\n",
       "      <td>6</td>\n",
       "      <td>490_3</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>310</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>225</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>134.004264</td>\n",
       "      <td>178.672352</td>\n",
       "      <td>852</td>\n",
       "      <td>1136</td>\n",
       "      <td>0.131091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33704</th>\n",
       "      <td>490_3_250</td>\n",
       "      <td>6</td>\n",
       "      <td>490_3</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>310</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>225</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>134.004264</td>\n",
       "      <td>178.672352</td>\n",
       "      <td>852</td>\n",
       "      <td>1136</td>\n",
       "      <td>0.131091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33705</th>\n",
       "      <td>490_3_251</td>\n",
       "      <td>6</td>\n",
       "      <td>490_3</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>310</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>225</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>134.004264</td>\n",
       "      <td>178.672352</td>\n",
       "      <td>852</td>\n",
       "      <td>1136</td>\n",
       "      <td>0.131091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33706</th>\n",
       "      <td>490_3_252</td>\n",
       "      <td>6</td>\n",
       "      <td>490_3</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>310</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>225</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>134.004264</td>\n",
       "      <td>178.672352</td>\n",
       "      <td>852</td>\n",
       "      <td>1136</td>\n",
       "      <td>0.131091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33707 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  Class  video  measures        ps  frames_n  measure_scaled  \\\n",
       "0         6_2_35      4    6_2     16.47  0.120130        51        0.618863   \n",
       "1         6_2_36      4    6_2     16.47  0.120130        51        0.618863   \n",
       "2         6_2_37      4    6_2     16.47  0.120130        51        0.618863   \n",
       "3         6_2_38      4    6_2     16.47  0.120130        51        0.618863   \n",
       "4         6_2_39      4    6_2     16.47  0.120130        51        0.618863   \n",
       "...          ...    ...    ...       ...       ...       ...             ...   \n",
       "33702  490_3_248      6  490_3      6.10  0.157282       310        0.139177   \n",
       "33703  490_3_249      6  490_3      6.10  0.157282       310        0.139177   \n",
       "33704  490_3_250      6  490_3      6.10  0.157282       310        0.139177   \n",
       "33705  490_3_251      6  490_3      6.10  0.157282       310        0.139177   \n",
       "33706  490_3_252      6  490_3      6.10  0.157282       310        0.139177   \n",
       "\n",
       "       days  frame_loc      height       width  height_org  width_org  \\\n",
       "0       147   0.686275   86.493600  115.324800         720        960   \n",
       "1       147   0.705882   86.493600  115.324800         720        960   \n",
       "2       147   0.725490   86.493600  115.324800         720        960   \n",
       "3       147   0.745098   86.493600  115.324800         720        960   \n",
       "4       147   0.764706   86.493600  115.324800         720        960   \n",
       "...     ...        ...         ...         ...         ...        ...   \n",
       "33702   225   0.800000  134.004264  178.672352         852       1136   \n",
       "33703   225   0.803226  134.004264  178.672352         852       1136   \n",
       "33704   225   0.806452  134.004264  178.672352         852       1136   \n",
       "33705   225   0.809677  134.004264  178.672352         852       1136   \n",
       "33706   225   0.812903  134.004264  178.672352         852       1136   \n",
       "\n",
       "       measure_normalized  \n",
       "0                0.457089  \n",
       "1                0.457089  \n",
       "2                0.457089  \n",
       "3                0.457089  \n",
       "4                0.457089  \n",
       "...                   ...  \n",
       "33702            0.131091  \n",
       "33703            0.131091  \n",
       "33704            0.131091  \n",
       "33705            0.131091  \n",
       "33706            0.131091  \n",
       "\n",
       "[33707 rows x 14 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_vids = (val['video'].value_counts() > 3)\n",
    "videos = val['video'].unique()\n",
    "long_vids = videos[long_vids]\n",
    "val_filtered = val[val['video'].isin(long_vids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_filtered.to_csv('/data/kpusteln/Fetal-RL/data_preparation/data_biometry/ete_model/biometry_scaled_ps/all/key_frame_data/biometry_val_all_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(num, min_value, max_value):\n",
    "   return max(min(num, max_value), min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video_Loader():\n",
    "    def __init__(self, root, videos_path, ann_path, transform=None, target_transform=None, img_scaling = False):\n",
    "        \n",
    "        self.data_path = root\n",
    "        self.ann_path = ann_path\n",
    "        self.videos = pd.read_csv(videos_path)\n",
    "        self.data = pd.read_csv(self.ann_path)\n",
    "        self.img_scaling = img_scaling\n",
    "        \n",
    "        \n",
    "    def _load_image(self, path):\n",
    "        try:\n",
    "            im = Image.open(path)\n",
    "            im.convert('RGB')\n",
    "        except:\n",
    "            print(\"ERROR IMG LOADED: \", path)\n",
    "            random_img = np.random.rand(224, 224, 3) * 255\n",
    "            im = Image.fromarray(np.uint8(random_img))\n",
    "        return im\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def _load_item(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        idb = self.data[data['index'] == index]\n",
    "        frame_idx = idb[0]\n",
    "        Class = torch.tensor(idb[1])\n",
    "        video = idb[2]\n",
    "        measure = torch.tensor(idb[3])\n",
    "        ps = torch.tensor(idb[4])\n",
    "        frames_n = torch.tensor(idb[5])\n",
    "        measure_scaled = torch.tensor(idb[6], dtype=torch.float32)\n",
    "        days_normalized = torch.tensor(idb[7], dtype=torch.float32)\n",
    "        frame_loc = torch.tensor(idb[8], dtype=torch.float32)\n",
    "        height = torch.tensor(idb[9])\n",
    "        width = torch.tensor(idb[10])\n",
    "        measure_normalized = torch.tensor(idb[13], dtype=torch.float32)\n",
    "        images = self._load_image(self.data_path  + frame_idx + '.png')\n",
    "        \n",
    "        new_height = clamp(int(height*2.161191086437513), 0, 512)\n",
    "        new_width = clamp(int(width*2.161191086437513), 0, 512)\n",
    "        if self.img_scaling:\n",
    "            padding = A.PadIfNeeded(min_height=512, min_width=512, border_mode=0, value=0, mask_value=0, always_apply=False, p=1.0)\n",
    "            rescale = A.Resize(new_height, new_width)\n",
    "            images = rescale(image = images)['image']\n",
    "            images = padding(image=images)['image']\n",
    "            images = np.expand_dims(images, 2)\n",
    "            t = transforms.Compose([transforms.ToTensor(),])\n",
    "            images = t(images)\n",
    "        else:\n",
    "            images = np.expand_dims(images, 2)\n",
    "            t = transforms.Compose([transforms.ToTensor(),\n",
    "            transforms.Resize((450, 600)),\n",
    "            transforms.Pad((0, 0, 0, 150), fill = 0, padding_mode = 'constant'),\n",
    "            transforms.Resize((512, 512)),\n",
    "            transforms.Normalize(mean=0.1354949, std=0.18222201)])\n",
    "            images = t(images)\n",
    "        if self.transform is not None:\n",
    "            images = self.transform(images)\n",
    "\n",
    "        return images, Class, measure, ps, frames_n, measure_scaled, index, days_normalized, frame_loc, measure_normalized\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        video = self.videos[index]\n",
    "        batch = self.data[self.data['video'] == video].sample(8)\n",
    "        frame_idx = batch['index']\n",
    "        images = list()\n",
    "        Classes = list()\n",
    "        indexes = list()\n",
    "        for i in frame_idx:\n",
    "            image, Class, measure, ps, frame_n, measure_scaled, index, days_normalized, frame_loc, measure_normalized = self._load_item(i)\n",
    "            images.append(image)\n",
    "            Classes.append(Class)\n",
    "            indexes.append(index)\n",
    "        return images, Classes, measure_scaled, ps, frame_n, measure_scaled, index, days_normalized, frame_loc, measure_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_padding(features, max_length):\n",
    "    padding_length = max_length - features.size(1)\n",
    "    padded_seq = torch.nn.functional.pad(features, (0, 0, 0, padding_length, 0, 0), mode='constant', value=0)\n",
    "    return padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq = features_padding(original_seq, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def mask_sequence(padded_seq, org_seq_len, max_len):  \n",
    "    \n",
    "    # Define the padded sequence\n",
    "    \n",
    "    padded_seq = torch.randn(1, max_len, 1280)\n",
    "\n",
    "    # Define the mask tensor\n",
    "    mask = torch.zeros(padded_seq.size()[:2], dtype=torch.float32)\n",
    "\n",
    "    # Set the non-padding elements to 1's\n",
    "    mask[:, :org_seq_len] = 1\n",
    "\n",
    "    # Expand the mask tensor to shape (1, 8, 1) and (1, 1, 8)\n",
    "    mask_1 = mask.unsqueeze(1)\n",
    "    mask_2 = mask.unsqueeze(2)\n",
    "\n",
    "    # Compute the element-wise multiplication of the two mask tensors\n",
    "    attention_mask = mask_1 * mask_2\n",
    "\n",
    "    # The attention mask has shape (1, 8, 8)\n",
    "    return attention_mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask_sequence(original_seq, 4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = torch.randn(1, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.0653e-01,  1.0171e+00,  1.2028e+00,  1.0150e+00, -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "         [ 2.2674e-01,  2.0132e-01, -1.3626e-01, -4.3834e-01, -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "         [ 1.7038e+00,  8.7594e-01,  1.0507e+00,  5.6731e-01, -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "         [-2.0116e-01,  6.3637e-01,  8.5214e-01,  8.1813e-01, -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09, -1.0000e+09]]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores.masked_fill(mask == 0, value=-1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pool_mask(features, org_seq_len):\n",
    "    features[:, org_seq_len:, :]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1280])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq[:, :3, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b772ba6196d99b64d9019a11b57c24f8066632039bdf84a783d1d6c99c4aa12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
